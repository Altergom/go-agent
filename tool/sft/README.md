# 🧠 SFT (监督微调) 教学指南

欢迎来到 SFT 工具箱！如果你是 AI 领域的新手，这篇文档将带你用最通俗易懂的方式理解什么是 **SFT** 以及它是如何让大模型“进化”的。

---

## 1. 什么是 SFT？(Supervised Fine-Tuning)

### 🏫 老师与学生的比喻
想象一下，你有一个非常聪明但“不修边幅”的学生（**通用大模型**，如 GPT-4 或 豆包）。他读过世界上所有的书，知道很多知识，但他不知道如何按照你的要求写出一份标准的“银行离职报告”。

**SFT 就是“手把手教学”的过程：**
1. **准备教材**：你搜集了 100 份完美的离职报告模板。
2. **闭卷考试**：让学生写，如果他写错了，你就把正确的标准答案给他看。
3. **刻意练习**：重复多次后，学生就学会了这种特定的写作风格和格式。

**结论**：SFT 是通过 **“问题 + 标准答案”** 的数据对，让通用模型变成某个领域“专家”的过程。

---

## 2. 为什么需要 SFT？

大模型虽然博学，但在以下场景需要 SFT：
*   **统一格式**：让模型始终返回 JSON 或特定的 Markdown 格式。
*   **学习私有知识**：让模型学习你们公司的内部业务代码或文档。
*   **调整语气**：让模型说话更像一个“资深 Go 程序员”或者“温柔的客服小姐姐”。
*   **间接蒸馏（我们正在做的）**：让昂贵的大模型（老师）教便宜的小模型（学生），从而在降低成本的同时保留智力。

---

## 3. 核心技术：LoRA (低秩自适应)

在 SFT 过程中，你可能会听到 **LoRA** 这个词。它是目前最流行的微调技术。

### 📝 “便利贴”比喻
大模型有数千亿个参数，就像一辆精密的赛车。如果你想改变赛车的性能：
*   **全量微调**：拆掉整台引擎重新组装（极度耗钱，极度耗时）。
*   **LoRA**：不碰原始引擎，而在引擎旁边贴上一张**“神奇的便利贴”**。

---

## 4. LoRA 的核心数学原理：低秩分解 (Low-Rank Decomposition)

> **面试重点提示**：面试官常问“LoRA 为什么有效？”、“秩（Rank）设置多少合适？”。

### 4.1 数学公式
在大模型推理时，每一层实际上都在做矩阵乘法：$h = W_0 x$。
LoRA 认为，微调的过程本质上是给原始权重 $W_0$ 增加一个增量 $\Delta W$。即：
$$W = W_0 + \Delta W$$

在全量微调中，$\Delta W$ 的大小和 $W_0$ 一模一样。而 LoRA 通过**低秩分解**，将 $\Delta W$ 分解为两个极小的矩阵 $A$ 和 $B$ 的乘积：
$$\Delta W = B \times A$$

*   **$W_0$**：原始权重矩阵，维度是 $(d \times k)$。**（冻结，不训练）**
*   **$A$**：维度是 $(r \times k)$。**（训练中）**，通常用高斯分布初始化。
*   **$B$**：维度是 $(d \times r)$。**（训练中）**，通常初始化为全 0（保证训练开始时 $\Delta W=0$）。
*   **$r$**：这就是 **秩 (Rank)**。

### 4.2 为什么能省钱？（参数量对比）
假设模型某层的维度 $d=4096, k=4096$：
*   **全量微调参数**：$4096 \times 4096 \approx 16,770,000$ 个参数。
*   **LoRA (若 $r=8$)**：
    *   矩阵 $A$：$8 \times 4096 = 32,768$ 个参数。
    *   矩阵 $B$：$4096 \times 8 = 32,768$ 个参数。
    *   **总计**：$65,536$ 个参数。

**结论**：参数量减少了 **250 倍** 以上！这就是为什么一张普通的家用显卡也能微调大模型。

### 4.3 为什么它有效？（Intrinsic Dimension 理论）
面试时可以提到：LoRA 的基础是 **内在维度 (Intrinsic Dimension)** 理论。
该理论认为：虽然模型参数很多（高维），但为了完成特定任务，真正起作用的参数变化其实在一个很小的子空间（低维）内。因此，我们设置一个很小的 $r$（如 8 或 16），就足以捕捉到任务相关的特征变化。

---

## 5. 我们项目中的 SFT 流程

本项目实现了一套自动化的“数据工厂”：

1.  **数据采集 (`callback.go`)**：当你在使用 Agent 时，系统会自动记下所有的对话。
2.  **自动标注 (`annotator.go`)**：
    *   我们请出一个**“教师模型”**（更强、更贵的模型）。
    *   老师会批改你的 Agent 的回答。
    *   老师会写下**“更完美的答案”**（Correction）。
3.  **样本存储 (`storage.go`)**：将老师批改好的卷子存起来。
4.  **导出训练 (`Export`)**：最后，你把这些“名师批改过”的卷子导出来，塞进训练平台（如火山方舟），你的模型就能进化了！

---

## 💡 总结
*   **SFT** = 模仿标准答案。
*   **LoRA** = 高效的微调补丁。
*   **蒸馏** = 大模型教小模型。

通过这套工具，你不需要自己写数据集，只要不断使用你的 Agent，它就会在后台自动积累知识，变得越来越聪明。
